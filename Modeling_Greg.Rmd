---
title: "Home Credit Modeling - Greg Francom"
output: html_notebook
---


Home Credit Risk

Load libraries
```{r}
install.packages("corrplot")


#library(xgboost) # for xgboost
library(tidyverse)# general utility functions
library(corrplot)
library(knitr) 
library(ggplot2) # Data visualization
#library(readr) # CSV file I/O, e.g. the read_csv function
library(caret)
#library(DMwR) # smote
library(Matrix)
#library(reshape) #melt
library(pROC) # AUC
library(gridExtra)
library(scales)
```

```{r}
# loading files
application_train <- read_csv("application_train.csv")

#there are a lot of rows, let's take a sample
#at <- application_train #|> sample_n(10000)
train <- application_train #|> sample_n(10000)

```


```{r}
sapply(back_order_data,class)
lapply(df, class)

lapply(df, class)
```

Which columns have missing data?
```{r}
#NAcol <- which(colSums(is.na(train)) > 0)
#sort(colSums(sapply(all[NAcol], is.na)), decreasing = TRUE)
skim(train)
train |> skim() |> filter(complete_rate) 
```

Variable selection 01
```{r}
trainchoice01<-train[,c("TARGET","DAYS_BIRTH","DAYS_EMPLOYED","DAYS_REGISTRATION","AMT_ANNUITY","AMT_CREDIT","AMT_INCOME_TOTAL","AMT_GOODS_PRICE","REGION_POPULATION_RELATIVE","CNT_CHILDREN","CNT_FAM_MEMBERS","FLAG_MOBIL","FLAG_EMP_PHONE","FLAG_WORK_PHONE","FLAG_PHONE","CODE_GENDER","FLAG_OWN_CAR","FLAG_OWN_REALTY")]

skim(trainchoice01)
```


```{r}
# Data imputation and cleanup
trainchoice01$AMT_GOODS_PRICE[is.na(trainchoice01$AMT_GOODS_PRICE)] <- 450000 #median 
trainchoice01$AMT_ANNUITY[is.na(trainchoice01$AMT_ANNUITY)] <- 24903 #median
trainchoice01$CNT_FAM_MEMBERS[is.na(trainchoice01$CNT_FAM_MEMBERS)] <- 1 
#trainchoice01$DAYS_BIRTH<-trainchoice01[,"DAYS_BIRTH"]/-365 #changes to df??

#df["group_b"][df["group_b"] == 11] <- 77
trainchoice01["DAYS_EMPLOYED"][trainchoice01["DAYS_EMPLOYED"] == 365243] <- -1213 #replace error outlier with median
#trainchoice01$DAYS_EMPLOYED<-trainchoice01[,"DAYS_EMPLOYED"]*-1 # created a dataframe??
#trainchoice01$DAYS_REGISTRATION <-trainchoice01[,"DAYS_REGISTRATION"]*-1

skim(trainchoice01)
```



```{r}
# Factor target variable
trainchoice01$TARGET<-as.factor(trainchoice01$TARGET)
trainchoice01[, c("FLAG_MOBIL","FLAG_EMP_PHONE","FLAG_WORK_PHONE","FLAG_PHONE","CODE_GENDER","FLAG_OWN_CAR","FLAG_OWN_REALTY")] <- lapply(trainchoice01[,c("FLAG_MOBIL","FLAG_EMP_PHONE","FLAG_WORK_PHONE","FLAG_PHONE","CODE_GENDER","FLAG_OWN_CAR","FLAG_OWN_REALTY")], as.factor)
trainchoice01$CNT_CHILDREN<-as.numeric(trainchoice01$CNT_CHILDREN)

trainchoice01$DAYS_BIRTH<-as.numeric(trainchoice01$DAYS_BIRTH)
skim(trainchoice01)
```






Test Models
```{r}
Model1 <- glm(TARGET ~ ., data = trainchoice01, family = binomial(link = "logit"))
summary(Model1)

basicplot1 <- ggplot(roc_d, aes(d = ground_truth, m = Model1)) + geom_roc()
#AIC: 166480
```







##Tasks
1. Identify the performance benchmark established by the majority class classifier. 
```{r}
#prop.table(table(hacide.train$cls))
prop.table(table(application_train$TARGET))
mean(application_train$TARGET)*100

application_train %>% 
  summarize(default = mean(TARGET==1))

orig.default*100

# Majority class is 91.93%. Target variable of default is 8.07%
```

2. Fit several different logistic regression models using different predictors. Do interaction terms improve the model?  Compare model performance using not just accuracy but also AUC.
```{r}

```




